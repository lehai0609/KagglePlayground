{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1xbnioxtuSA8UPkgojpXe4RP2Bk6WApJv",
      "authorship_tag": "ABX9TyPqz2nOo8lQUQz3+nTh/JX4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lehai0609/KagglePlayground/blob/main/PlaygroundS05E06_LightGBM_and_Improving_031.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import data"
      ],
      "metadata": {
        "id": "4dmxC5Jegw9i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79dc4993"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Define the base folder path\n",
        "base_folder = '/content/drive/MyDrive/Kaggle/Playground S5E6'\n",
        "\n",
        "# Import train.csv as synthetic_df\n",
        "synthetic_df = pd.read_csv(os.path.join(base_folder, 'train.csv'))\n",
        "test_df = pd.read_csv(os.path.join(base_folder, 'test.csv'))\n",
        "original_df = pd.read_csv(os.path.join(base_folder, 'Fertilizer Prediction.csv'))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F55s5Bmn00O5",
        "outputId": "7a3f25f4-8601-4070-f9fd-d16a00b36c31"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 9 columns):\n",
            " #   Column           Non-Null Count   Dtype \n",
            "---  ------           --------------   ----- \n",
            " 0   Temparature      100000 non-null  int64 \n",
            " 1   Humidity         100000 non-null  int64 \n",
            " 2   Moisture         100000 non-null  int64 \n",
            " 3   Soil Type        100000 non-null  object\n",
            " 4   Crop Type        100000 non-null  object\n",
            " 5   Nitrogen         100000 non-null  int64 \n",
            " 6   Potassium        100000 non-null  int64 \n",
            " 7   Phosphorous      100000 non-null  int64 \n",
            " 8   Fertilizer Name  100000 non-null  object\n",
            "dtypes: int64(6), object(3)\n",
            "memory usage: 6.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDCrQ605goB1",
        "outputId": "cf1a27f2-ab4b-4106-8f7d-2903ce055962"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 750000 entries, 0 to 749999\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count   Dtype \n",
            "---  ------           --------------   ----- \n",
            " 0   id               750000 non-null  int64 \n",
            " 1   Temparature      750000 non-null  int64 \n",
            " 2   Humidity         750000 non-null  int64 \n",
            " 3   Moisture         750000 non-null  int64 \n",
            " 4   Soil Type        750000 non-null  object\n",
            " 5   Crop Type        750000 non-null  object\n",
            " 6   Nitrogen         750000 non-null  int64 \n",
            " 7   Potassium        750000 non-null  int64 \n",
            " 8   Phosphorous      750000 non-null  int64 \n",
            " 9   Fertilizer Name  750000 non-null  object\n",
            "dtypes: int64(7), object(3)\n",
            "memory usage: 57.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preparation for modelling\n",
        "\n",
        "Use basic lightGBM for baseline modelling.\n",
        "- Encode categorical features & target"
      ],
      "metadata": {
        "id": "ctmf0lZ80Hnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle Categorical variables\n",
        "categorical_features = ['Soil Type', 'Crop Type']\n",
        "for col in categorical_features:\n",
        "  synthetic_df[col] = synthetic_df[col].astype('category')\n",
        "  test_df[col] = test_df[col].astype('category')\n",
        "  original_df[col] = original_df[col].astype('category')"
      ],
      "metadata": {
        "id": "P_A7D0cn0mhg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "# Fertilizer Name is my target variable. And it should be encoded as categorical data too.\n",
        "target_col = 'Fertilizer Name'\n",
        "feature_cols = ['Soil Type', 'Crop Type', 'Humidity', 'Temparature', 'Moisture', 'Nitrogen', 'Potassium']\n",
        "\n",
        "X = synthetic_df[feature_cols]\n",
        "y = synthetic_df[target_col]\n",
        "X_original = original_df[feature_cols]\n",
        "y_original = original_df[target_col]\n",
        "\n",
        "# If target is categorical, encode it\n",
        "if y.dtype == 'object':\n",
        "    target_encoder = LabelEncoder()\n",
        "    y_encoded = target_encoder.fit_transform(y)\n",
        "    y = y_encoded\n",
        "\n",
        "if y_original.dtype == 'object':\n",
        "    target_encoder = LabelEncoder()\n",
        "    y_original_encoded = target_encoder.fit_transform(y_original)\n",
        "    y_original = y_original_encoded\n",
        "\n",
        "\n",
        "# Define LightGBM parameters\n",
        "params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': len(np.unique(y)),\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1,  # Suppress output\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Custom MAP@3 calculation function\n",
        "def mapk(y_true, y_pred_proba, k=3):\n",
        "    \"\"\"Calculate MAP@k score\"\"\"\n",
        "    # Get top k predictions for each sample\n",
        "    top_k = np.argsort(y_pred_proba, axis=1)[:, -k:][:, ::-1]\n",
        "\n",
        "    scores = []\n",
        "    for i, true_label in enumerate(y_true):\n",
        "        # Get rank of true label in top k predictions\n",
        "        try:\n",
        "            rank = np.where(top_k[i] == true_label)[0][0] + 1\n",
        "            if rank <= k:\n",
        "                scores.append(1.0 / rank)\n",
        "            else:\n",
        "                scores.append(0.0)\n",
        "        except IndexError:\n",
        "            scores.append(0.0)\n",
        "\n",
        "    return np.mean(scores)"
      ],
      "metadata": {
        "id": "5e26ZtqW1p4d"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start 5-Fold cross-validation\n",
        "# Initialize stratified 5 folds\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store scores\n",
        "cv_scores = []\n",
        "cv_map3_scores = []\n",
        "models = []\n",
        "\n",
        "# Create a train/validation loop through defined (X, y) above, in that\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"Fold {fold + 1} out of 5\")\n",
        "    # Split data\n",
        "    X_train_synthetic, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train_synthetic, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    # Concatenate original data to training set\n",
        "    X_train_combined = pd.concat([X_train_synthetic, X_original], ignore_index=True)\n",
        "    y_train_combined = np.concatenate([y_train_synthetic, y_original])\n",
        "\n",
        "    # Create train & val dataset for lightGBM\n",
        "    train_data = lgb.Dataset(X_train_combined, label=y_train_combined)\n",
        "    val_data = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "    # Train the model\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        train_data,\n",
        "        valid_sets=[val_data],\n",
        "        num_boost_round=500,\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(0)])\n",
        "\n",
        "    # Make prediction on val data\n",
        "    val_pred_proba = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "    val_pred_classes = np.argmax(val_pred_proba, axis=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_val, val_pred_classes)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    map3_score = mapk(y_val, val_pred_proba, k=3)\n",
        "    print(f\"MAP@3 Score: {map3_score}\")\n",
        "\n",
        "    # Append scores\n",
        "    cv_scores.append(accuracy)\n",
        "    cv_map3_scores.append(map3_score)\n",
        "    models.append(model)\n",
        "# Print Cross-Validation Results\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"CROSS-VALIDATION RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Accuracy - Mean: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
        "print(f\"MAP@3 - Mean: {np.mean(cv_map3_scores):.4f} ± {np.std(cv_map3_scores):.4f}\")\n",
        "print(\"\\nFold-by-fold MAP@3 scores:\")\n",
        "for i, score in enumerate(cv_map3_scores):\n",
        "    print(f\"Fold {i+1}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWvvbiTV3r4E",
        "outputId": "09acb276-1ebf-4011-a41a-1a1299402ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 out of 5\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\tvalid_0's multi_logloss: 1.92198\n",
            "Accuracy: 0.19229333333333334\n",
            "MAP@3 Score: 0.327\n",
            "Fold 2 out of 5\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\tvalid_0's multi_logloss: 1.92161\n",
            "Accuracy: 0.1931\n",
            "MAP@3 Score: 0.3278155555555555\n",
            "Fold 3 out of 5\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\tvalid_0's multi_logloss: 1.92184\n",
            "Accuracy: 0.19307333333333335\n",
            "MAP@3 Score: 0.32740888888888886\n",
            "Fold 4 out of 5\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\tvalid_0's multi_logloss: 1.92223\n",
            "Accuracy: 0.19274666666666668\n",
            "MAP@3 Score: 0.3271333333333333\n",
            "Fold 5 out of 5\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Output the Map@3 testing"
      ],
      "metadata": {
        "id": "yFC_LRAa5Pbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = pd.read_csv(os.path.join(base_folder, 'sample_submission.csv'))\n",
        "sample_df.head()"
      ],
      "metadata": {
        "id": "Z4R6tCr35VnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGenerating test predictions...\")\n",
        "# Prepare Test features\n",
        "test_features = test_df[feature_cols]\n",
        "\n",
        "# Average predictions from all folds\n",
        "test_pred_avg = np.zeros((len(test_df), len(np.unique(y))))\n",
        "for model in models:\n",
        "    test_pred = model.predict(test_features, num_iteration=model.best_iteration)\n",
        "    test_pred_avg += test_pred / len(models)\n",
        "\n",
        "# Get top 3 indices\n",
        "top3_indices = np.argsort(test_pred_avg, axis=1)[:, -3:][:, ::-1]\n",
        "\n",
        "# Convert indices back to fertilizer names\n",
        "fertilizer_names = target_encoder.inverse_transform(top3_indices.flatten()).reshape(-1, 3)\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'Fertilizer Name': [' '.join(row) for row in fertilizer_names]\n",
        "})\n",
        "\n",
        "# Save submission\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(submission.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pP_dqwX6n8l",
        "outputId": "5ac1a15a-e221-4417-c1a9-1d894fbea881"
      },
      "execution_count": 71,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating test predictions...\n",
            "       id             Fertilizer Name\n",
            "0  750000          28-28 10-26-26 DAP\n",
            "1  750001     17-17-17 20-20 10-26-26\n",
            "2  750002     20-20 14-35-14 10-26-26\n",
            "3  750003  14-35-14 17-17-17 10-26-26\n",
            "4  750004        20-20 28-28 10-26-26\n"
          ]
        }
      ]
    }
  ]
}